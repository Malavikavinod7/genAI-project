{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0edfe851-6047-4e19-be32-ca603f7aa5b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed wget-3.2\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from lomond->ibm-watson-machine-learning>=1.0.310) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget | tail -n 1\n",
    "!pip install scikit-learn | tail -n 1\n",
    "!pip install \"ibm-watson-machine-learning>=1.0.310\" | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a315a448-709c-46f4-a783-aae0f62bbd64"
   },
   "outputs": [],
   "source": [
    "url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "apikey='enter your api key '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ca351cf3-3e55-42b0-8a83-55b1bf903e95"
   },
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"url\": url,\n",
    "    \"apikey\": apikey\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "606c104b-4f34-466a-9841-93681e09430d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3b65b630-96b0-413b-bbd3-5511f839b826'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")\n",
    "\n",
    "\n",
    "project_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4aebe93b-6a43-4ecb-a9c5-5779e500b1f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The plaintiff's claims are dismissed.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The contract is deemed valid and enforceable.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The appeal is denied due to lack of merit.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The legal team submitted additional evidence.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The appeal is under consideration.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The settlement agreement is fair and reasonable.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>The appeal is under consideration.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The settlement agreement is fair and reasonable.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>The court reviewed the documentation.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The contract is deemed valid and enforceable.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                            Phrase  Sentiment\n",
       "0   1             The plaintiff's claims are dismissed.         -1\n",
       "1   2     The contract is deemed valid and enforceable.          1\n",
       "2   3        The appeal is denied due to lack of merit.         -1\n",
       "3   4     The legal team submitted additional evidence.          0\n",
       "4   5                The appeal is under consideration.          0\n",
       "5   6  The settlement agreement is fair and reasonable.          1\n",
       "6   7                The appeal is under consideration.          0\n",
       "7   8  The settlement agreement is fair and reasonable.          1\n",
       "8   9             The court reviewed the documentation.          0\n",
       "9  10     The contract is deemed valid and enforceable.          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "from io import StringIO # Import StringIO\n",
    "\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='AcSmvalVuyr5r5PkpmIuQGX7fxkfDPw_MmSvusXFd27a',  # Your secret API key\n",
    "    ibm_auth_endpoint='https://iam.cloud.ibm.com/oidc/token',\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.us-south.cloud-object-storage.appdomain.cloud'\n",
    ")\n",
    "\n",
    "bucket = 'bucket-n38x7k26jbac15c'\n",
    "object_key = 'legal_sentiment_dataset (1).csv'\n",
    "\n",
    "# Get the object content\n",
    "body = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Read the content into a string\n",
    "csv_string = body.read().decode('utf-8')\n",
    "\n",
    "# Use StringIO to treat the string as a file\n",
    "data = pd.read_csv(StringIO(csv_string))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bf9229c5-c729-4701-aabb-ff7214124eee"
   },
   "outputs": [],
   "source": [
    "label_map={\n",
    "    -1:'negative',\n",
    "     0:'netural',\n",
    "     1: 'positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b59ee2b3-dd4f-4b33-a121-a97e35cf0dc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       " 1           184\n",
       "-1           167\n",
       " 0           149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts(['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7389a82d-3fd0-4404-8048-414dfb272d12"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "    data['Phrase'],\n",
    "    data['Sentiment'],\n",
    "    test_size=0.3,\n",
    "    random_state=33,\n",
    "    stratify=data['Sentiment']\n",
    ")\n",
    "\n",
    "# Convert to DataFrames\n",
    "data_train = pd.DataFrame({'Phrase': data_train, 'Sentiment': y_train})\n",
    "data_test = pd.DataFrame({'Phrase': data_test, 'Sentiment': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2a5799b5-7d03-4421-bd6a-8be6ff777a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FLAN_T5_XXL', 'FLAN_UL2', 'MT0_XXL', 'GPT_NEOX', 'MPT_7B_INSTRUCT2', 'STARCODER', 'LLAMA_2_70B_CHAT', 'LLAMA_2_13B_CHAT', 'GRANITE_13B_INSTRUCT', 'GRANITE_13B_CHAT', 'FLAN_T5_XL', 'GRANITE_13B_CHAT_V2', 'GRANITE_13B_INSTRUCT_V2', 'ELYZA_JAPANESE_LLAMA_2_7B_INSTRUCT', 'MIXTRAL_8X7B_INSTRUCT_V01_Q', 'CODELLAMA_34B_INSTRUCT_HF', 'GRANITE_20B_MULTILINGUAL']\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "print([model.name for model in ModelTypes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "53f3faa8-2353-4f09-bc95-11e9e496ef17"
   },
   "outputs": [],
   "source": [
    "model_id = ModelTypes.FLAN_T5_XXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "008638ee-e94a-468e-9ad3-2dfcafbbda29"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.RANDOM_SEED: 33,\n",
    "    GenParams.REPETITION_PENALTY: 1,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97d233ad-73a1-47f6-9397-ee55a21d5bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model object initialized successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/utils/utils.py:273: LifecycleWarning: Model 'google/flan-ul2' is in deprecated state from 2025-05-28 until 2025-07-30. IDs of alternative models: None. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warnings.warn(default_warning_template.format(\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "\n",
    "# Ensure these are correctly defined\n",
    "model_id = \"google/flan-ul2\" # Example model ID\n",
    "parameters = {\n",
    "    \"decoding_method\": \"greedy\",\n",
    "    \"min_new_tokens\": 10,\n",
    "    \"max_new_tokens\": 50\n",
    "}\n",
    "credentials = {\n",
    "    \"apikey\": \"enter your apikey\", # Replace with your actual API key\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\" # Replace with your WML service endpoint URL\n",
    "}\n",
    "project_id = \"3b65b630-96b0-413b-bbd3-5511f839b826\" # Replace with your actual project ID\n",
    "\n",
    "try:\n",
    "    model = Model(\n",
    "        model_id=model_id,\n",
    "        params=parameters,\n",
    "        credentials=credentials,\n",
    "        project_id=project_id\n",
    "    )\n",
    "    print(\"Model object initialized successfully!\")\n",
    "    # You can now use the 'model' object for inference\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model initialization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "f51b64eb-b515-4c7f-bcd1-12e19220d10f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'google/flan-ul2',\n",
       " 'label': 'flan-ul2-20b',\n",
       " 'provider': 'Google',\n",
       " 'source': 'Hugging Face',\n",
       " 'functions': [{'id': 'autoai_rag'}, {'id': 'text_generation'}],\n",
       " 'short_description': 'flan-ul2 is an encoder decoder model based on the T5 architecture and instruction-tuned using the Fine-tuned Language Net.',\n",
       " 'long_description': 'flan-ul2 (20B) is an encoder decoder model based on the T5 architecture and instruction-tuned using the Fine-tuned Language Net (FLAN). Compared to the original UL2 model, flan-ul2 (20B) is more usable for few-shot in-context learning because it was trained with a three times larger receptive field. flan-ul2 (20B) outperforms flan-t5 (11B) by an overall relative improvement of +3.2%.',\n",
       " 'terms_url': 'https://huggingface.co/google/flan-ul2/blob/main/README.md',\n",
       " 'input_tier': 'class_3',\n",
       " 'output_tier': 'class_3',\n",
       " 'number_params': '20b',\n",
       " 'min_shot_size': 0,\n",
       " 'task_ids': ['question_answering',\n",
       "  'summarization',\n",
       "  'retrieval_augmented_generation',\n",
       "  'classification',\n",
       "  'generation',\n",
       "  'extraction',\n",
       "  'translation'],\n",
       " 'tasks': [{'id': 'question_answering', 'ratings': {'quality': 4}},\n",
       "  {'id': 'summarization', 'ratings': {'quality': 4}},\n",
       "  {'id': 'retrieval_augmented_generation', 'ratings': {'quality': 4}},\n",
       "  {'id': 'classification', 'ratings': {'quality': 4}},\n",
       "  {'id': 'generation'},\n",
       "  {'id': 'extraction', 'ratings': {'quality': 4}},\n",
       "  {'id': 'translation'}],\n",
       " 'model_limits': {'max_sequence_length': 4096, 'max_output_tokens': 4095},\n",
       " 'limits': {'lite': {'call_time': '5m0s', 'max_output_tokens': 4095},\n",
       "  'v2-professional': {'call_time': '10m0s', 'max_output_tokens': 4095},\n",
       "  'v2-standard': {'call_time': '10m0s', 'max_output_tokens': 4095}},\n",
       " 'lifecycle': [{'id': 'available', 'start_date': '2023-07-07'},\n",
       "  {'id': 'deprecated', 'start_date': '2025-05-28'},\n",
       "  {'id': 'withdrawn', 'start_date': '2025-07-30'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dd4d04cf-5d33-4b9e-a112-9883251be865"
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"Determine the sentiment of the sentence.\n",
    "Use either 'positive', 'negative', 'neutral'. Use the provided examples as a template.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "f43d6814-44fe-451a-b11d-4b4b4cec16ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence example 1 is:\n",
      "\t The legal team submitted additional evidence.\n",
      "\n",
      "The sentence example 2 is:\n",
      "\t The appeal is denied due to lack of merit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero_shot_inputs = [{\"input\": text} for text in data_test['Phrase']]\n",
    "for i in range(2):\n",
    "    print(f\"The sentence example {i+1} is:\\n\\t {zero_shot_inputs[i]['input']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "f470eec3-ce04-4e5f-a2de-bad0dcd6ba39"
   },
   "outputs": [],
   "source": [
    "data_train_and_labels = data_train.copy()\n",
    "data_train_and_labels['Sentiment'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "87f7a190-1acc-4702-b411-5326c86e20a5"
   },
   "outputs": [],
   "source": [
    "few_shot_example = []\n",
    "few_shot_examples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "07b7989d-8d71-4649-baa4-c8f56f214c95"
   },
   "outputs": [],
   "source": [
    "for phrase, sentiment in data_train_and_labels \\\n",
    "    .groupby('Sentiment') \\\n",
    "    .apply(lambda x: x.sample(2)).values:\n",
    "    \n",
    "    few_shot_example.append(f\"\\tsentence:\\t{phrase}\\n\\tsentiment: {sentiment}\\n\")\n",
    "\n",
    "few_shot_examples = '\\n'.join(few_shot_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "e7d3ffc8-6674-494d-b875-48c2c500fe02"
   },
   "outputs": [],
   "source": [
    "few_shot_inputs_ = [{\"input\": text} for text in data_test['Phrase'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "204d2244-6589-44e1-9c49-943471443c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence example 1 is:\n",
      " The legal team submitted additional evidence.\n",
      "\n",
      "\tSentiment: 0\n",
      "\n",
      "The sentence example 2 is:\n",
      " The appeal is denied due to lack of merit.\n",
      "\n",
      "\tSentiment: -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(f\"The sentence example {i+1} is:\\n {few_shot_inputs_[i]['input']}\\n\")\n",
    "    print(f\"\\tSentiment: {y_test.iloc[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bdce05eb-2f0e-4036-b7d4-eade23151684"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for inp in few_shot_inputs_[:2]:\n",
    "    results.append(\n",
    "        model.generate(\" \".join([instruction + few_shot_examples[0], inp['input']]))[\"results\"][0]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ab8edcf9-e5c2-465e-a8b7-0901131727d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"generated_text\": \"neutral.. . . . . . . . . . . . . . . . . . . . . . . . \",\n",
      "    \"generated_token_count\": 50,\n",
      "    \"input_token_count\": 42,\n",
      "    \"stop_reason\": \"max_tokens\"\n",
      "  },\n",
      "  {\n",
      "    \"generated_text\": \"negative.. . . . . . . . . . . . . . . . . . . . . . . . \",\n",
      "    \"generated_token_count\": 50,\n",
      "    \"input_token_count\": 45,\n",
      "    \"stop_reason\": \"max_tokens\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "e87ce834-36bf-468f-9494-4c7d2a8c911c"
   },
   "outputs": [],
   "source": [
    "y_pred = [result['generated_text'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "06d409cc-d368-4269-b932-9f4440e6a535"
   },
   "outputs": [],
   "source": [
    "y_true = [label_map[label] for label in y_test.values[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8431d48f-7dd6-4b10-bb9d-cc760873d140"
   },
   "outputs": [],
   "source": [
    "few_shot_examples_str = '\\n'.join(few_shot_example) \n",
    "\n",
    "results = []\n",
    "for inp_dict in few_shot_inputs_: # Iterate over ALL test inputs\n",
    "    # Construct the full prompt for each test input\n",
    "    full_prompt = f\"{instruction}\\n\\n{few_shot_examples_str}\\n\\nText: {inp_dict['input']}\\nSentiment:\"\n",
    "\n",
    "    try:\n",
    "        # Generate prediction\n",
    "        generated_text = model.generate_text(prompt=full_prompt)\n",
    "        results.append({'generated_text': generated_text.strip()}) \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating for input: {inp_dict['input']} - {e}\")\n",
    "        results.append({'generated_text': 'ERROR'}) \n",
    "\n",
    "y_pred = [result['generated_text'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "3f9ecf6b-d2a0-455b-8f01-320617c4abcd"
   },
   "outputs": [],
   "source": [
    "cleaned_y_pred = []\n",
    "for pred in y_pred:\n",
    "    pred_lower = pred.lower().strip()\n",
    "    if 'positive' in pred_lower:\n",
    "        cleaned_y_pred.append('positive')\n",
    "    elif 'negative' in pred_lower:\n",
    "        cleaned_y_pred.append('negative')\n",
    "    elif 'neutral' in pred_lower or 'netural' in pred_lower: # Handle typo if model generates it\n",
    "        cleaned_y_pred.append('neutral')\n",
    "    else:\n",
    "        cleaned_y_pred.append('unknown') # Handle cases where model doesn't give expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "106e3b1a-fc42-43b2-9211-990c74f4808f"
   },
   "outputs": [],
   "source": [
    "y_true_strings = [label_map[label] for label in y_test.values] # Apply to full y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "c9661e8a-be89-4d6f-83f7-0c7f1847d975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of data_test['Phrase']: 150\n",
      "Length of data_test['Sentiment']: 150\n",
      "Length of y_true_strings: 150\n",
      "Length of cleaned_y_pred: 150\n",
      "\n",
      "Full results saved to legal_sentiment_analysis_results.csv\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Accuracy: 0.38666666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.58      0.73        50\n",
      "     netural       0.00      0.00      0.00        45\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "    positive       1.00      0.53      0.69        55\n",
      "     unknown       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39       150\n",
      "   macro avg       0.40      0.22      0.28       150\n",
      "weighted avg       0.70      0.39      0.50       150\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[29  0 12  0  9]\n",
      " [ 0  0 45  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0 26 29  0]\n",
      " [ 0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "    data['Phrase'],\n",
    "    data['Sentiment'],\n",
    "    test_size=0.3,\n",
    "    random_state=33,\n",
    "    stratify=data['Sentiment']\n",
    ")\n",
    "\n",
    "# Convert to DataFrames\n",
    "data_train = pd.DataFrame({'Phrase': data_train, 'Sentiment': y_train})\n",
    "data_test = pd.DataFrame({'Phrase': data_test, 'Sentiment': y_test})\n",
    "\n",
    "\n",
    "y_true_strings = [label_map[label] for label in data_test['Sentiment'].values] # <--- FIX IS HERE\n",
    "\n",
    "# --- Verify lengths again (after the fix) ---\n",
    "print(f\"\\nLength of data_test['Phrase']: {len(data_test['Phrase'])}\")\n",
    "print(f\"Length of data_test['Sentiment']: {len(data_test['Sentiment'])}\") # Should now be 150\n",
    "print(f\"Length of y_true_strings: {len(y_true_strings)}\") # Should now be 150\n",
    "print(f\"Length of cleaned_y_pred: {len(cleaned_y_pred)}\") # Should be 150 if inference worked fully\n",
    "\n",
    "# --- Create DataFrame and Save ---\n",
    "# Now, all lengths should match, and this will execute without error\n",
    "results_df = pd.DataFrame({\n",
    "    'Phrase': data_test['Phrase'].tolist(),\n",
    "    'True_Sentiment': y_true_strings,\n",
    "    'Predicted_Sentiment': cleaned_y_pred\n",
    "})\n",
    "\n",
    "csv_file_name = 'legal_sentiment_analysis_results.csv'\n",
    "results_df.to_csv(csv_file_name, index=False)\n",
    "print(f\"\\nFull results saved to {csv_file_name}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true_strings, cleaned_y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true_strings, cleaned_y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true_strings, cleaned_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "02753885-560f-4aff-a91c-774a2dcd9d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to sentiment_analysis_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame from your results\n",
    "results_df = pd.DataFrame({\n",
    "    'Phrase': data_test['Phrase'].tolist(), # Use the full test phrases\n",
    "    'True_Sentiment': [lable_map[label] for label in y_test.values], # Use the full y_test\n",
    "    'Predicted_Sentiment': cleaned_y_pred # This should contain predictions for the full test set\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('sentiment_analysis_results.csv', index=False)\n",
    "print(\"Results saved to sentiment_analysis_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afb2e499-98c4-45d1-b364-8b573d066a5a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
